{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2ba87-55d6-4ae3-bbc8-f8adbb963507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 1\n",
    "Underfitting means that your model makes accurate, but initially incorrect predictions. \n",
    "In this case, train error is large and val/test error is large too. \n",
    "\n",
    "Overfitting means that your model makes not accurate predictions. \n",
    "In this case, train error is very small and val/test error is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774462a0-8a08-4767-a5c5-58e1abbea115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 2\n",
    "we can reduce overfitting by using these methods -\n",
    "ensembling\n",
    "data augmentation\n",
    "data simplification\n",
    "cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f69ac3-97e8-4086-afd2-a4846e4e6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 3\n",
    "\n",
    "Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data.\n",
    "\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404ff1a-1fca-4270-863c-bc2021ecc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans 4\n",
    "\n",
    "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict.\n",
    "\n",
    "Variance is the variability of model prediction for a given data point or a value which tells us spread of our data.\n",
    "\n",
    "“Bias and variance are complements of each other” The increase of one will result in the decrease of the other and vice versa. Hence, finding the right balance of values is known as the Bias-Variance Tradeoff. Target Function. An ideal algorithm should neither underfit nor overfit the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308d168-236d-4d78-b348-5f2d5a005f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 5\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871a3f8-8adb-4447-acda-725167727926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 6\n",
    "The term \"variance\" refers to the degree of change that may be expected in the estimation of the target function as a result of using multiple sets of training data. The disparity between the values that were predicted and the values that were actually observed is referred to as bias\n",
    "\n",
    "example of high bias :-Linear Regression, Linear Discriminant Analysis and Logistic Regression.\n",
    "\n",
    "example of high varience :- Decision Trees, k-Nearest Neighbors and Support Vector Machines.\n",
    "\n",
    "A model with high variance may represent the data set accurately but could lead to overfitting to noisy or otherwise unrepresentative training data. \n",
    "In comparison, a model with high bias may underfit the training data due to a simpler model that overlooks regularities in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25182f3-8c5c-40dc-ae52-62b475b8730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans 7\n",
    "Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.\n",
    "Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it.\n",
    "\n",
    "Regularization is used in machine learning as a solution to overfitting by reducing the variance of the ML model under consideration.\n",
    "Regularization can be implemented in multiple ways by either modifying the loss function, sampling method, or the training approach itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
